{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3750916-7bed-41c2-829a-0259dc44c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705fac6d-c30b-4e90-b480-21113a63c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "# test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "# test_df = test_df.drop(['Name'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0945606f-8d12-41b9-a529-146541700422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced feature engineering\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    # Create family size feature\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    \n",
    "    # Create is_alone feature\n",
    "    dataset['IsAlone'] = 1\n",
    "    dataset.loc[dataset['FamilySize'] > 1, 'IsAlone'] = 0\n",
    "    \n",
    "    # Extract title from name\n",
    "    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # Group rare titles\n",
    "    rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "    dataset['Title'] = dataset['Title'].replace(rare_titles, 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Extract ticket prefix and ticket length\n",
    "    dataset['TicketPrefix'] = dataset['Ticket'].str.extract('([A-Za-z]+)', expand=False)\n",
    "    dataset['TicketPrefix'] = dataset['TicketPrefix'].fillna('XXX')\n",
    "    dataset['TicketLen'] = dataset['Ticket'].str.len()\n",
    "\n",
    "    dataset['Age'] = pd.to_numeric(dataset['Age'], errors='coerce')\n",
    "    dataset['Age'] = dataset['Age'].fillna(dataset['Age'].median())\n",
    "    \n",
    "    # Create age bands\n",
    "    dataset['AgeBand'] = pd.cut(dataset['Age'], bins=[0, 16, 32, 48, 64, np.inf], labels=[0, 1, 2, 3, 4])\n",
    "    dataset['FamilySizeCategory'] = pd.cut(dataset['FamilySize'], bins=[0, 1, 4, np.inf], labels=['Small', 'Medium', 'Large'])\n",
    "    dataset['FamilySizeCategory'] = pd.Categorical(dataset['FamilySizeCategory']).codes\n",
    "\n",
    "    \n",
    "    # Create fare bands\n",
    "    dataset['FareBand'] = pd.qcut(dataset['Fare'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31df256e-d6e2-48b7-8c7c-f6df6eff497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced imputation\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "train_df[['Age', 'Fare']] = imputer.fit_transform(train_df[['Age', 'Fare']])\n",
    "test_df[['Age', 'Fare']] = imputer.transform(test_df[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a34247-f842-4e5f-b5b1-8d6814558dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['Age', 'Fare', 'FamilySize', 'TicketLen']\n",
    "train_df[numeric_features] = scaler.fit_transform(train_df[numeric_features])\n",
    "test_df[numeric_features] = scaler.transform(test_df[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6121df51-5ec3-44a5-b0d7-9a4b0271ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "categorical_features = ['Sex', 'Embarked', 'Title', 'TicketPrefix', 'AgeBand', 'FareBand']\n",
    "for feature in categorical_features:\n",
    "    train_df[feature] = pd.Categorical(train_df[feature]).codes\n",
    "    test_df[feature] = pd.Categorical(test_df[feature]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8feaefa1-c715-45f6-b95b-6b692bf49d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset in combine:\n",
    "#     dataset['Age*Class'] = dataset['Age'] * dataset['Pclass']\n",
    "#     dataset['Fare*Class'] = dataset['Fare'] * dataset['Pclass']\n",
    "#     dataset['Age*Title'] = dataset['Age'] * dataset['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c3dfdf-c830-4245-90fe-ba650253a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "selector = SelectKBest(f_classif, k=11)\n",
    "X = train_df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "y = train_df['Survived']\n",
    "X_selected = selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e523ed37-25a1-4ffa-b663-e9b484bf874c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 15), (891,), (418, 15))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1).copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f95e70-eba5-49bc-9f80-8b647df40103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.82"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "679ee154-cf93-4848-b941-1f46bf8dccab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.26"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0d7c033-292a-4e0a-9b9f-8992c2e0d575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.54"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bca45945-98b1-4a52-b51f-ecb9313e3edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.79"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a5dbb6c-1f9d-4696-b2f4-7e850e0a1e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.68"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "813232e8-1810-49c1-85ee-9d6c37afb975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "Y_pred = linear_svc.predict(X_test)\n",
    "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "329eb076-d8af-455a-97f6-7102f000ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.78"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b4a6788-21c4-497e-a75c-728f91078bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.65"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edf82657-dd22-402b-acea-3403b0db84e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.65"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e953d669-271b-41c7-9e0d-12dcccc6efb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>98.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>98.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>87.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>81.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>81.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>81.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>78.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>78.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>66.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Score\n",
       "3               Random Forest  98.65\n",
       "8               Decision Tree  98.65\n",
       "1                         KNN  87.54\n",
       "2         Logistic Regression  81.82\n",
       "0     Support Vector Machines  81.26\n",
       "7                  Linear SVC  81.14\n",
       "4                 Naive Bayes  78.79\n",
       "5                  Perceptron  78.68\n",
       "6  Stochastic Gradient Decent  66.78"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e2c7d8-7a10-454c-b800-cb1d08ff38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with Random Forest\n",
    "pipelines = {\n",
    "    'Support Vector Machines': Pipeline([('classifier', SVC(random_state=42))]),\n",
    "    'KNN': Pipeline([('classifier', KNeighborsClassifier())]),\n",
    "    'Logistic Regression': Pipeline([('classifier', LogisticRegression(random_state=42))]),\n",
    "    'Random Forest': Pipeline([('classifier', RandomForestClassifier(n_estimators=100, random_state=42))]),\n",
    "    'Naive Bayes': Pipeline([('classifier', GaussianNB())]),\n",
    "    'Perceptron': Pipeline([('classifier', Perceptron(random_state=42))]),\n",
    "    'Stochastic Gradient Descent': Pipeline([('classifier', SGDClassifier(random_state=42))]),\n",
    "    'Linear SVC': Pipeline([('classifier', LinearSVC(random_state=42))]),\n",
    "    'Decision Tree': Pipeline([('classifier', DecisionTreeClassifier(random_state=42))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "366006c8-e692-41d2-8f79-d1162c5650b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__max_depth': [5, 10, None],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    # Perform GridSearchCV\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    if model_name in param_grid:\n",
    "        grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    else:\n",
    "        grid_search = GridSearchCV(pipeline, {}, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    grid_search.fit(X_selected, y)\n",
    "    \n",
    "    # Get best model and its score\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_score = grid_search.best_score_\n",
    "    \n",
    "    # print(f\"{model_name} Accuracy: {best_score:.4f}\")\n",
    "    # print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6d564a1-7589-4659-af0b-5106cc67178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Ensemble Model Average Accuracy: 0.8541\n",
      "Best RandomForest Parameters: {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 104}\n",
      "Best XGBoost Parameters: {'colsample_bytree': 0.6624074561769746, 'learning_rate': 0.05679835610086079, 'max_depth': 5, 'n_estimators': 187, 'subsample': 0.7334834444556088}\n",
      "Best LightGBM Parameters: {'colsample_bytree': 0.7394663949166917, 'learning_rate': 0.03885296532742623, 'max_depth': 3, 'n_estimators': 227, 'num_leaves': 58, 'subsample': 0.9746919954946938}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Remove the 'classifier__' prefix from the best parameters\n",
    "rf_params = {k.replace('classifier__', ''): v for k, v in grid_search.best_params_.items()}\n",
    "\n",
    "# Define parameter distributions for RandomizedSearchCV\n",
    "rf_param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': [None] + list(range(5, 30)),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "lgb_param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'num_leaves': randint(20, 100),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform RandomizedSearchCV for each classifier\n",
    "rf_random = RandomizedSearchCV(RandomForestClassifier(**rf_params), param_distributions=rf_param_dist, n_iter=50, cv=cv, random_state=42, n_jobs=-1)\n",
    "xgb_random = RandomizedSearchCV(XGBClassifier(), param_distributions=xgb_param_dist, n_iter=50, cv=cv, random_state=42, n_jobs=-1)\n",
    "lgb_random = RandomizedSearchCV(LGBMClassifier(verbose=-1), param_distributions=lgb_param_dist, n_iter=50, cv=cv, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "rf_random.fit(X_selected, y)\n",
    "xgb_random.fit(X_selected, y)\n",
    "lgb_random.fit(X_selected, y)\n",
    "\n",
    "# Create ensemble with tuned models\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_random.best_estimator_),\n",
    "        ('xgb', xgb_random.best_estimator_),\n",
    "        ('lgb', lgb_random.best_estimator_)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Evaluate ensemble\n",
    "ensemble_scores = cross_val_score(ensemble, X_selected, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Tuned Ensemble Model Average Accuracy: {ensemble_scores.mean():.4f}\")\n",
    "\n",
    "# Print best parameters for each model\n",
    "print(\"Best RandomForest Parameters:\", rf_random.best_params_)\n",
    "print(\"Best XGBoost Parameters:\", xgb_random.best_params_)\n",
    "print(\"Best LightGBM Parameters:\", lgb_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6085d2-a2bd-4952-801a-c23431a5cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
